// server.js - Real-time Translation Backend
// Gerekli paketler: npm install express ws openai dotenv cors

import express from 'express';
import { WebSocketServer, WebSocket } from 'ws';
import OpenAI from 'openai';
import cors from 'cors';
import dotenv from 'dotenv';

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json());

const PORT = process.env.PORT || 3001;

// OpenAI Client - Dinamik API key ile baÅŸlatÄ±lacak
let openai = null;

// OpenAI client'Ä± baÅŸlat
const initializeOpenAI = (apiKey) => {
  if (!openai) {
    openai = new OpenAI({
      apiKey: apiKey || process.env.OPENAI_API_KEY,
    });
    console.log('ğŸ”‘ OpenAI client initialized');
  }
  return openai;
};

// Session Management
const sessions = new Map();

class TranscriptionSession {
  constructor(ws) {
    this.ws = ws;
    this.realtimeWs = null;
    this.contextBuffer = []; // Son 60 saniye transkript
    this.pendingCorrections = [];
    this.currentContext = '';
    this.currentLanguage = 'en'; // Default language
    this.sampleRate = 24000; // Default sample rate
    this.sessionStartTime = Date.now();
    this.lastAnalysisTime = Date.now();
    
    // YENÄ°: Optimizasyon parametreleri
    this.minAnalysisInterval = 2000; // 5s yerine 2s
    this.transcriptsSinceLastAnalysis = 0;
    this.transcriptThreshold = 3; // 3 transcript gelince analiz et
    this.lastTranscriptTime = Date.now();
    this.correctionCache = new Map(); // DÃ¼zeltme Ã¶nbelleÄŸi
    this.targetLanguage = 'en'; // Hedef Ã§eviri dili
    
    // ğŸ†• ADIM 2.2: Keyword cache (performans optimizasyonu)
    this.keywordCache = new Map(); // Context â†’ keywords mapping
    this.KEYWORD_CACHE_TTL = 60000; // 60 saniye cache
    
    // ğŸ†• ADIM 1.0a: Atomik ID sistemi
    this.chunkCounter = 0; // Benzersiz ID iÃ§in sayaÃ§
    this.chunksMap = new Map(); // ID â†’ Chunk mapping
    
    // ğŸ†• ADIM 1.4: Cleanup mekanizmasÄ±
    this.MAX_CHUNKS = 200; // Maksimum chunk sayÄ±sÄ±
    this.CLEANUP_INTERVAL = 30000; // 30 saniye cleanup
    this.startCleanupTimer();
  }
  
  // ğŸ†• ADIM 1.4: Periyodik cleanup
  startCleanupTimer() {
    this.cleanupTimer = setInterval(() => {
      this.cleanupOldChunks();
    }, this.CLEANUP_INTERVAL);
  }
  
  // ğŸ†• ADIM 1.4: Eski chunk'larÄ± temizle
  cleanupOldChunks() {
    const chunkCount = this.chunksMap.size;
    
    if (chunkCount <= this.MAX_CHUNKS) {
      console.log(`âœ… Chunk cleanup: ${chunkCount}/${this.MAX_CHUNKS} (OK)`);
      return;
    }
    
    // En eski chunk'larÄ± sil (FIFO)
    const chunksToDelete = chunkCount - this.MAX_CHUNKS;
    const sortedChunks = Array.from(this.chunksMap.keys()).sort();
    
    for (let i = 0; i < chunksToDelete; i++) {
      const chunkId = sortedChunks[i];
      this.chunksMap.delete(chunkId);
      console.log(`ğŸ—‘ï¸ Deleted old chunk: ${chunkId}`);
    }
    
    console.log(`âœ… Chunk cleanup: ${this.chunksMap.size}/${this.MAX_CHUNKS} (Cleaned ${chunksToDelete} chunks)`);
  }

  // Rolling context window (60 saniye)
  addToContext(text, timestamp, id) { // ğŸ†• YENÄ°: id parametresi eklendi
    this.contextBuffer.push({ id, text, timestamp }); // ğŸ†• id eklendi
    this.transcriptsSinceLastAnalysis++;
    this.lastTranscriptTime = timestamp;
    
    // 60 saniyeden eski kayÄ±tlarÄ± temizle
    const cutoffTime = Date.now() - 60000;
    this.contextBuffer = this.contextBuffer.filter(
      item => item.timestamp > cutoffTime
    );
    
    this.currentContext = this.contextBuffer
      .map(item => item.text)
      .join(' ');
  }

  // YENÄ°: AkÄ±llÄ± tetikleme - birden fazla koÅŸul
  shouldTriggerAnalysis() {
    const timeSinceLastAnalysis = Date.now() - this.lastAnalysisTime;
    const timeSinceLastTranscript = Date.now() - this.lastTranscriptTime;
    
    return (
      // KoÅŸul 1: Minimum sÃ¼re geÃ§ti VE yeni transkript var
      (timeSinceLastAnalysis > this.minAnalysisInterval && 
       this.transcriptsSinceLastAnalysis > 0) ||
      
      // KoÅŸul 2: Belirli sayÄ±da transkript birikti
      this.transcriptsSinceLastAnalysis >= this.transcriptThreshold ||
      
      // KoÅŸul 3: KonuÅŸma durdu (2 saniye sessizlik)
      timeSinceLastTranscript > 2000
    );
  }

  // OpenAI Realtime API'ye baÄŸlan
  async connectToRealtime() {
    try {
      console.log('ğŸ”Œ Connecting to OpenAI Realtime API...');
      
      // OpenAI client'Ä± baÅŸlat
      const openaiClient = initializeOpenAI(process.env.OPENAI_API_KEY);
      
      // WebSocket baÄŸlantÄ±sÄ± kur (dokÃ¼mantasyona gÃ¶re)
      const ws = new WebSocket(
        `wss://api.openai.com/v1/realtime?model=gpt-realtime`,
        {
          headers: {
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          },
        }
      );

      this.realtimeWs = ws;

      ws.on('open', () => {
        console.log('âœ… Connected to OpenAI Realtime API');
        
        // Session update gÃ¶nder (dokÃ¼mantasyona gÃ¶re)
        ws.send(JSON.stringify({
          type: 'session.update',
          session: {
            type: 'realtime',
            model: 'gpt-realtime',
            instructions: 'You are a helpful assistant for real-time speech transcription and translation.',
            audio: {
              input: {
                format: {
                  type: 'audio/pcm',
                  rate: this.sampleRate, // Dinamik sample rate
                },
                turn_detection: {
                  type: 'server_vad',
                  threshold: 0.5,
                  prefix_padding_ms: 300,
                  silence_duration_ms: 500,
                },
                transcription: {
                  model: 'gpt-4o-transcribe',
                  prompt: '',
                  language: this.currentLanguage, // Use session language
                },
              },
              output: {
                format: {
                  type: 'audio/pcm',
                  rate: this.sampleRate, // Dinamik sample rate
                },
                voice: 'alloy',
              },
            },
          },
        }));
        
        this.ws.send(JSON.stringify({
          type: 'status',
          message: 'Connected to transcription service',
        }));
      });

      ws.on('message', async (data) => {
        const event = JSON.parse(data.toString());
        await this.handleRealtimeEvent(event);
      });

      ws.on('error', (error) => {
        console.error('âŒ Realtime API error:', error);
        this.ws.send(JSON.stringify({
          type: 'error',
          message: 'Transcription service error',
        }));
      });

      ws.on('close', () => {
        console.log('ğŸ”Œ Disconnected from OpenAI Realtime API');
      });

    } catch (error) {
      console.error('âŒ Failed to connect to Realtime API:', error);
    }
  }

  // Realtime API eventlerini iÅŸle
  async handleRealtimeEvent(event) {
    switch (event.type) {
      case 'session.created':
        console.log('âœ… Realtime session created');
        break;
        
      case 'session.updated':
        console.log('âœ… Realtime session updated');
        break;

      case 'conversation.item.input_audio_transcription.completed':
        const transcript = event.transcript;
        const timestamp = Date.now();
        const chunkId = `chunk-${Date.now()}-${this.chunkCounter++}`; // ğŸ†• ADIM 1.0a: Benzersiz ID
        
        console.log('ğŸ“ Transcript:', transcript, '| ID:', chunkId); // ğŸ†• ID de logla
        
        // ğŸ†• ADIM 1.0a: Chunks map'e ekle
        this.chunksMap.set(chunkId, {
          id: chunkId,
          text: transcript,
          timestamp,
          corrected: false,
          translationSent: false
        });
        
        // Context buffer'a ekle (ÅŸimdi ID ile)
        this.addToContext(transcript, timestamp, chunkId); // ğŸ†• chunkId parametresi eklendi
        
        // Client'a gÃ¶nder (ID ile)
        this.ws.send(JSON.stringify({
          type: 'transcript',
          data: {
            id: chunkId, // ğŸ†• YENÄ°: ID eklendi
            text: transcript,
            timestamp,
            corrected: false,
          },
        }));
        
        // ğŸ”§ FIX: Her chunk iÃ§in tetikle (shouldTriggerAnalysis kontrolÃ¼ kaldÄ±rÄ±ldÄ±)
        // Paralel Ã§alÄ±ÅŸtÄ±r: dÃ¼zeltme ve Ã§eviriyi aynÄ± anda baÅŸlat
        Promise.all([
          this.analyzeAndCorrect(),
          this.autoTranslate(chunkId) // Her chunk iÃ§in Ã§eviri
        ]).catch(err => console.error('Analysis error:', err));
        
        break;

      case 'conversation.item.input_audio_transcription.failed':
        console.error('âŒ Transcription failed:', event.error);
        break;
        
      case 'input_audio_buffer.speech_started':
        console.log('ğŸ¤ Speech started');
        break;
        
      case 'input_audio_buffer.speech_stopped':
        console.log('ğŸ¤ Speech stopped');
        break;
        
      case 'input_audio_buffer.committed':
        console.log('âœ… Audio buffer committed');
        break;
        
      case 'error':
        console.error('âŒ Realtime API error:', event.error);
        this.ws.send(JSON.stringify({
          type: 'error',
          message: event.error?.message || 'Unknown error',
        }));
        break;
    }
  }

  // ğŸ†• ADIM 2.1: Dinamik prompt builder
  async buildDynamicPrompt(context) {
    try {
      // ğŸ†• ADIM 2.2: Keyword cache kontrolÃ¼ (performans)
      const cacheKey = context.slice(-100); // Son 100 karakter key olarak
      const cached = this.keywordCache.get(cacheKey);
      
      let keywords;
      if (cached && Date.now() - cached.timestamp < this.KEYWORD_CACHE_TTL) {
        keywords = cached.keywords;
        console.log('âœ… Using cached keywords:', keywords);
      } else {
        // ADIM 1: GPT ile keyword extraction (baÄŸlamsal analiz iÃ§in)
        // ğŸ”§ FIX: Session'daki API key kullan (this.apiKey)
        const keywordResponse = await initializeOpenAI(this.apiKey || process.env.OPENAI_API_KEY).chat.completions.create({
          model: 'gpt-4o-mini',
          messages: [{
            role: 'user',
            content: `Extract 3-5 key topics, entities, or context clues from this transcript. 
Ignore filler words. Focus on what the user is talking about.
Return comma-separated list:

"${context}"

Key topics:`
          }],
          max_tokens: 30,
          temperature: 0.3
        });
        
        keywords = keywordResponse.choices[0].message.content.trim();
        
        // Cache'e ekle
        this.keywordCache.set(cacheKey, {
          keywords,
          timestamp: Date.now()
        });
        
        console.log('ğŸ”‘ Extracted keywords:', keywords);
      }
      
      // ADIM 2: BaÄŸlamsal prompt oluÅŸtur
      return `Analyze this speech transcript for transcription errors.

Context clues (what user is talking about): ${keywords}

Text: "${context}"

Consider:
1. Homophones based on context (e.g., "resim" vs "sesim" in mic test)
2. Entity names that match the context
3. Technical terms related to: ${keywords}

Return JSON:
{
  "topic": "${keywords}",
  "corrections": [{"original": "X", "corrected": "Y", "confidence": 0.9}]
}`;

    } catch (error) {
      console.error('âŒ Keyword extraction failed:', error);
      // Fallback: basit prompt
      return `Analyze this speech transcript for entity errors.

Text: "${context}"

Return JSON:
{
  "topic": "general",
  "corrections": [{"original": "X", "corrected": "Y", "confidence": 0.9}]
}`;
    }
  }

  // YENÄ°: Cache'li dÃ¼zeltme
  async analyzeAndCorrect() {
    // ğŸ”§ FIX: Minimum context kontrolÃ¼ kaldÄ±rÄ±ldÄ± - ilk cÃ¼mleden itibaren dÃ¼zelt
    if (this.currentContext.length < 5) return; // Sadece Ã§ok kÄ±sa metinleri atla

    try {
      // Cache kontrolÃ¼ - son 20 kelimeyi key olarak kullan
      const contextKey = this.currentContext.split(' ').slice(-20).join(' ');
      const cached = this.correctionCache.get(contextKey);
      
      if (cached && Date.now() - cached.timestamp < 30000) {
        console.log('âœ… Using cached corrections');
        this.sendCorrections(cached.data);
        return;
      }

      console.log('ğŸ” Analyzing context...');
      
      // ğŸ†• ADIM 2.4: Performans optimizasyonu
      const recentContext = this.currentContext.slice(-200);
      
      // Background'da keyword extraction (bekleme yok!)
      this.buildDynamicPrompt(recentContext).catch(err => 
        console.error('âŒ Keyword extraction background error:', err)
      );
      
      // HÄ±zlÄ± prompt kullan (keyword extraction beklemeden)
      const quickPrompt = `Analyze this speech transcript for transcription errors.

Text: "${recentContext}"

Common errors:
- Homophones (hear/here, see/sea)
- Entity names
- Technical terms

Return JSON:
{
  "topic": "detected topic",
  "corrections": [{"original": "X", "corrected": "Y", "confidence": 0.9}]
}`;
      
      // ğŸ”§ FIX: Session'daki API key kullan (this.apiKey)
      const response = await initializeOpenAI(this.apiKey || process.env.OPENAI_API_KEY).chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: 'You are an expert at correcting speech transcription errors. Respond with JSON only.',
          },
          {
            role: 'user',
            content: quickPrompt,
          },
        ],
        temperature: 0.2,
        max_tokens: 200,
        response_format: { type: 'json_object' },
      });

      const result = JSON.parse(response.choices[0].message.content);
      
      if (result.corrections && result.corrections.length > 0) {
        console.log('âœ… Found corrections:', result.corrections);
        
        // Cache'e ekle
        this.correctionCache.set(contextKey, {
          data: result,
          timestamp: Date.now()
        });
        
        this.sendCorrections(result);
      }

    } catch (error) {
      console.error('âŒ Correction failed:', error);
    }
  }

  sendCorrections(result) {
    this.ws.send(JSON.stringify({
      type: 'corrections',
      data: {
        topic: result.topic,
        corrections: result.corrections,
      },
    }));
    
    // ğŸ†• ADIM 1.0d: DÃ¼zeltme sonrasÄ± yeniden Ã§eviri
    if (result.corrections && result.corrections.length > 0) {
      this.retranslateAffectedChunks(result.corrections);
    }
  }
  
  // ğŸ†• ADIM 1.0d: Etkilenen chunk'larÄ± yeniden Ã§evir
  async retranslateAffectedChunks(corrections) {
    if (!this.targetLanguage || this.targetLanguage === 'Original') return;
    
    // Her dÃ¼zeltme iÃ§in etkilenen chunk'larÄ± bul
    corrections.forEach(async (correction) => {
      // chunksMap'te dÃ¼zeltilen kelimeyi iÃ§eren chunk'larÄ± bul
      for (const [chunkId, chunk] of this.chunksMap.entries()) {
        if (chunk.text.includes(correction.original)) {
          console.log(`ğŸ”„ Retranslating chunk ${chunkId}: "${correction.original}" â†’ "${correction.corrected}"`);
          
          // DÃ¼zeltilmiÅŸ metni oluÅŸtur
          const correctedText = chunk.text.replace(
            new RegExp(correction.original, 'gi'),
            correction.corrected
          );
          
          // Chunk'Ä± gÃ¼ncelle
          chunk.corrected = correctedText;
          
          // Yeniden Ã§evir
          await this.translate(correctedText, this.targetLanguage, chunkId);
        }
      }
    });
  }

  // YENÄ°: Otomatik Ã§eviri - HER CHUNK iÃ§in tetiklenir
  async autoTranslate(chunkId) { // ğŸ†• ADIM 1.0c: chunkId parametresi eklendi
    // ğŸ”§ FIX: Sadece bu chunk'Ä± Ã§evir (cumulative deÄŸil!)
    const chunk = this.chunksMap.get(chunkId);
    if (!chunk) return;
    
    const textToTranslate = chunk.text;
    if (textToTranslate.length < 5) return; // Ã‡ok kÄ±sa metinleri atla
    
    // Chunk'Ä± iÅŸaretle (Ã§eviri gÃ¶nderildi)
    chunk.translationSent = true;
    
    // Ã‡eviriyi baÅŸlat (sadece bu chunk'Ä±n metni)
    if (this.targetLanguage && this.targetLanguage !== 'Original') {
      await this.translate(textToTranslate, this.targetLanguage, chunkId);
    }
  }

  // Audio data gÃ¶nder
  sendAudio(audioData) {
    if (this.realtimeWs && this.realtimeWs.readyState === WebSocket.OPEN) {
      this.realtimeWs.send(JSON.stringify({
        type: 'input_audio_buffer.append',
        audio: audioData,
      }));
    }
  }

  async translate(text, targetLanguage, chunkId) { // ğŸ†• ADIM 1.0c: chunkId parametresi eklendi
    try {
      // ğŸ”§ ADIM 2.4.2: KÄ±sa prompt + dÃ¼ÅŸÃ¼k token
      const stream = await initializeOpenAI(process.env.OPENAI_API_KEY).chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: `Translate to ${targetLanguage}. Keep names as-is.`,
          },
          {
            role: 'user',
            content: text,
          },
        ],
        max_tokens: 150, // ğŸ”§ 300â†’150 (chunk'lar kÃ¼Ã§Ã¼k)
        temperature: 0.3, // ğŸ”§ Consistency iÃ§in
        stream: true,
      });

      // Stream baÅŸladÄ± iÅŸareti (ğŸ†• for_chunk_id eklendi)
      this.ws.send(JSON.stringify({
        type: 'translation_start',
        data: { 
          language: targetLanguage,
          for_chunk_id: chunkId // ğŸ†• ADIM 1.0c: Hangi chunk iÃ§in
        }
      }));

      // ğŸ”§ ADIM 2.4.3: Batching ile streaming optimize et
      let buffer = '';
      let lastSendTime = Date.now();
      const BATCH_INTERVAL = 50; // 50ms batching (UI iÃ§in daha akÄ±cÄ±)
      
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        if (content) {
          buffer += content;
          
          // 50ms'de bir veya buffer dolunca gÃ¶nder
          const now = Date.now();
          if (now - lastSendTime >= BATCH_INTERVAL || buffer.length > 50) {
            this.ws.send(JSON.stringify({
              type: 'translation',
              data: {
                text: buffer,
                language: targetLanguage,
                partial: true,
                for_chunk_id: chunkId // ğŸ†• ADIM 1.0c
              },
            }));
            buffer = '';
            lastSendTime = now;
          }
        }
      }
      
      // Kalan buffer'Ä± gÃ¶nder
      if (buffer) {
        this.ws.send(JSON.stringify({
          type: 'translation',
          data: {
            text: buffer,
            language: targetLanguage,
            partial: true,
            for_chunk_id: chunkId
          },
        }));
      }

      // Translation complete (ğŸ†• for_chunk_id eklendi)
      this.ws.send(JSON.stringify({
        type: 'translation',
        data: {
          language: targetLanguage,
          partial: false,
          for_chunk_id: chunkId // ğŸ†• ADIM 1.0c
        },
      }));

    } catch (error) {
      console.error('âŒ Translation failed:', error);
    }
  }

  disconnect() {
    // ğŸ†• ADIM 1.4: Cleanup timer'Ä± durdur
    if (this.cleanupTimer) {
      clearInterval(this.cleanupTimer);
      console.log('ğŸ›‘ Cleanup timer stopped');
    }
    
    if (this.realtimeWs) {
      this.realtimeWs.close();
    }
  }
}

// HTTP Server
const server = app.listen(PORT, () => {
  console.log(`ğŸš€ Server running on http://localhost:${PORT}`);
});

// WebSocket Server
const wss = new WebSocketServer({ 
  server,
  perMessageDeflate: false, // DÃ¼ÅŸÃ¼k latency iÃ§in
  maxPayload: 16 * 1024 * 1024, // 16MB max payload
});

wss.on('connection', (ws, req) => {
  console.log('ğŸ‘¤ New client connected from:', req.socket.remoteAddress);
  
  const sessionId = Math.random().toString(36).substring(7);
  const session = new TranscriptionSession(ws);
  sessions.set(sessionId, session);
  
  // BaÄŸlantÄ± onayÄ± gÃ¶nder
  ws.send(JSON.stringify({
    type: 'status',
    message: 'Connected successfully'
  }));

  ws.on('message', async (message) => {
    try {
      const data = JSON.parse(message.toString());

      switch (data.type) {
        case 'start':
          console.log('â–¶ï¸  Starting transcription session');
          if (data.apiKey) {
            // Frontend'den gelen API key'i kullan
            process.env.OPENAI_API_KEY = data.apiKey;
            console.log('ğŸ”‘ Using API key from frontend');
            // OpenAI client'Ä± yeniden baÅŸlat
            openai = null;
            initializeOpenAI(data.apiKey);
          } else if (!process.env.OPENAI_API_KEY) {
            ws.send(JSON.stringify({
              type: 'error',
              message: 'API key required'
            }));
            return;
          }
          
          // Dil bilgisini session'a kaydet
          if (data.language) {
            // ISO 639-1 dil kodlarÄ±nÄ± doÄŸrula
            const supportedLanguages = [
              'af', 'ar', 'az', 'be', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'iw', 'ja', 'kk', 'kn', 'ko', 'lt', 'lv', 'mi', 'mk', 'mr', 'ms', 'ne', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'sw', 'ta', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'zh'
            ];
            
            const languageCode = supportedLanguages.includes(data.language) ? data.language : 'en';
            
            if (languageCode !== data.language) {
              console.warn(`âš ï¸ Unsupported language '${data.language}', falling back to 'en'`);
            }
            
            session.currentLanguage = languageCode;
            console.log('ğŸŒ Language set to:', languageCode);
          }
          
          // YENÄ°: Hedef Ã§eviri dilini session'a kaydet
          if (data.targetLanguage) {
            session.targetLanguage = data.targetLanguage;
            console.log('ğŸ¯ Target language set to:', data.targetLanguage);
          }
          
          // Sample rate bilgisini session'a kaydet
          if (data.sampleRate) {
            // Desteklenen sample rate'leri kontrol et
            const supportedRates = [16000, 24000, 44100, 48000];
            const sampleRate = supportedRates.includes(data.sampleRate) ? data.sampleRate : 24000;
            
            if (sampleRate !== data.sampleRate) {
              console.warn(`âš ï¸ Unsupported sample rate '${data.sampleRate}', falling back to '24000'`);
            }
            
            session.sampleRate = sampleRate;
            console.log('ğŸµ Sample rate set to:', sampleRate);
          }
          
          await session.connectToRealtime();
          break;

        case 'audio':
          // Audio data from client (base64 PCM)
          session.sendAudio(data.audio);
          break;

        case 'translate':
          // Translation request
          await session.translate(data.text, data.targetLanguage);
          break;

        case 'update_language':
          console.log('ğŸŒ Updating language to:', data.language);
          
          // ISO 639-1 dil kodlarÄ±nÄ± doÄŸrula
          const supportedLanguages = [
            'af', 'ar', 'az', 'be', 'bg', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', 'fi', 'fr', 'gl', 'he', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'iw', 'ja', 'kk', 'kn', 'ko', 'lt', 'lv', 'mi', 'mk', 'mr', 'ms', 'ne', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sv', 'sw', 'ta', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'zh'
          ];
          
          const languageCode = supportedLanguages.includes(data.language) ? data.language : 'en';
          
          if (languageCode !== data.language) {
            console.warn(`âš ï¸ Unsupported language '${data.language}', falling back to 'en'`);
          }
          
          // Session'Ä±n dilini gÃ¼ncelle
          session.currentLanguage = languageCode;
          
          if (session.realtimeWs && session.realtimeWs.readyState === WebSocket.OPEN) {
            session.realtimeWs.send(JSON.stringify({
              type: 'session.update',
              session: {
                audio: {
                  input: {
                    transcription: {
                      language: languageCode,
                    },
                  },
                },
              },
            }));
          }
          break;

        case 'update_target_language':
          console.log('ğŸ¯ Updating target language to:', data.targetLanguage);
          session.targetLanguage = data.targetLanguage;
          break;

        case 'stop':
          console.log('â¹ï¸  Stopping transcription session');
          session.disconnect();
          break;
      }
    } catch (error) {
      console.error('âŒ Message handling error:', error);
      
      // Sadece aÃ§Ä±k baÄŸlantÄ±lara hata gÃ¶nder
      if (ws.readyState === ws.OPEN) {
        ws.send(JSON.stringify({
          type: 'error',
          message: 'Invalid message format'
        }));
      }
    }
  });

  ws.on('close', (code, reason) => {
    console.log('ğŸ‘‹ Client disconnected:', code, reason.toString());
    session.disconnect();
    sessions.delete(sessionId);
  });

  ws.on('error', (error) => {
    console.error('âŒ WebSocket error:', error);
    session.disconnect();
    sessions.delete(sessionId);
  });
  
  // Ping-pong ile baÄŸlantÄ±yÄ± canlÄ± tut
  const pingInterval = setInterval(() => {
    if (ws.readyState === ws.OPEN) {
      ws.ping();
    } else {
      clearInterval(pingInterval);
    }
  }, 30000); // 30 saniyede bir ping
  
  ws.on('pong', () => {
    // Pong geldi, baÄŸlantÄ± canlÄ±
  });
});

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    activeSessions: sessions.size,
    uptime: process.uptime(),
  });
});

console.log('ğŸ™ï¸  Real-time Translation Server Ready!');
console.log('ğŸ“¡ WebSocket endpoint: ws://localhost:' + PORT);
