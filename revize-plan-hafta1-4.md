# ğŸ¯ REVÄ°ZE EDÄ°LMÄ°Å PLAN - AI Ã–NERÄ°LERÄ° Ä°LE GÃœNCELLENDÄ°

> **Ã–nceki Plan**: 7.11.2205.md  
> **Revizyon**: ai-analiz-degerlendirme.md analizi sonrasÄ±  
> **Tarih**: 7 KasÄ±m 2025, 22:45  
> **DeÄŸiÅŸiklikler**: Atomik ID, Global dil, Context similarity, TTL queue

---

## ğŸ”„ NELERÄ° DEÄÄ°ÅTÄ°RDÄ°K?

### **KRÄ°TÄ°K DEÄÄ°ÅÄ°KLÄ°KLER (MUTLAKA UYGULANACAK):**

1. **âœ… HAFTA 1:** Atomik ID sistemi eklendi (race condition Ã§Ã¶zÃ¼mÃ¼)
2. **âœ… HAFTA 2:** Global dil desteÄŸi (stopWords kaldÄ±rÄ±ldÄ±, GPT-based keywords)
3. **âœ… HAFTA 3:** Candidate generation kaldÄ±rÄ±ldÄ± (context similarity kullanÄ±lacak)
4. **âœ… HAFTA 4:** TTL queue eklendi (memory leak Ã¶nleme)

### **KÃœÃ‡ÃœK Ä°YÄ°LEÅTÄ°RMELER:**

5. **âœ… HAFTA 1:** Unified state management (frontend)
6. **âœ… HAFTA 1:** Retranslation endpoint (backend)
7. **âš ï¸ HAFTA 1:** STT alternatives testi (varsa kullan)

---

# HAFTA 1: GERÃ‡EK ZAMANLI Ã‡EVÄ°RÄ° + ATOMÄ°K ID (REVÄ°ZE)

## **YENÄ° ADIM 1.0: Atomik ID Sistemi (GÃ¼n 0.5 - Ã–ncelik!)**

> **NEDEN Ã–NCE BU:** Race condition'sÄ±z sistem iÃ§in temel altyapÄ±

### **Backend: Chunk ID Sistemi**

#### **1. TranscriptionSession Constructor'a Ekle:**
```javascript
// backend/server.js: TranscriptionSession sÄ±nÄ±fÄ±
constructor(ws) {
  // ... mevcut kod
  this.chunkCounter = 0; // YENÄ°: Benzersiz ID iÃ§in sayaÃ§
  this.chunksMap = new Map(); // YENÄ°: ID â†’ Chunk mapping
}
```

#### **2. handleRealtimeEvent Fonksiyonunu DeÄŸiÅŸtir:**
```javascript
// backend/server.js: satÄ±r ~190
case 'conversation.item.input_audio_transcription.completed':
  const transcript = event.transcript;
  const timestamp = Date.now();
  const chunkId = `chunk-${Date.now()}-${this.chunkCounter++}`; // YENÄ°: Unique ID
  
  console.log('ğŸ“ Transcript:', transcript, 'ID:', chunkId);
  
  // âœ… TEST: STT alternatives varsa logla (ai-analiz BÃ¶lÃ¼m 2)
  if (event.alternatives && event.alternatives.length > 1) {
    console.log('âœ… STT Alternatives found:', event.alternatives);
    // Hafta 3'te kullanÄ±lacak
  } else {
    console.log('âš ï¸ No STT alternatives (confidence fusion disabled)');
  }
  
  // Context buffer'a ekle (ID ile)
  this.addToContext(transcript, timestamp, chunkId); // YENÄ° parametre
  
  // Chunks map'e ekle
  this.chunksMap.set(chunkId, {
    id: chunkId,
    text: transcript,
    timestamp,
    corrected: false,
    translationSent: false
  });
  
  // Client'a gÃ¶nder (ID ile)
  this.ws.send(JSON.stringify({
    type: 'transcript',
    data: {
      id: chunkId, // YENÄ°
      text: transcript,
      timestamp,
      corrected: false,
    },
  }));
  
  // Paralel Ã§alÄ±ÅŸtÄ±r (ID geÃ§)
  if (this.shouldTriggerAnalysis()) {
    this.lastAnalysisTime = Date.now();
    this.transcriptsSinceLastAnalysis = 0;
    
    Promise.all([
      this.analyzeAndCorrect(),
      this.autoTranslate(chunkId) // YENÄ°: ID ile Ã§aÄŸÄ±r
    ]).catch(err => console.error('Analysis error:', err));
  }
  break;
```

#### **3. addToContext Fonksiyonunu GÃ¼ncelle:**
```javascript
// backend/server.js: satÄ±r ~60
addToContext(text, timestamp, id) { // YENÄ° parametre
  this.contextBuffer.push({ id, text, timestamp }); // ID ekle
  this.transcriptsSinceLastAnalysis++;
  this.lastTranscriptTime = timestamp;
  
  // 60 saniyeden eski kayÄ±tlarÄ± temizle
  const cutoffTime = Date.now() - 60000;
  this.contextBuffer = this.contextBuffer.filter(
    item => item.timestamp > cutoffTime
  );
  
  this.currentContext = this.contextBuffer
    .map(item => item.text)
    .join(' ');
}
```

#### **4. autoTranslate Fonksiyonunu GÃ¼ncelle:**
```javascript
// backend/server.js: satÄ±r ~328
async autoTranslate(chunkId) { // YENÄ° parametre
  // Son 3 transkripti al
  const recentChunks = this.contextBuffer.slice(-3);
  const recentText = recentChunks.map(c => c.text).join(' ');
  
  if (recentText.length < 20) return;
  
  // Chunk'Ä± iÅŸaretle (Ã§eviri gÃ¶nderildi)
  const chunk = this.chunksMap.get(chunkId);
  if (chunk) {
    chunk.translationSent = true;
  }
  
  // Ã‡eviriyi baÅŸlat (ID ile)
  if (this.targetLanguage && this.targetLanguage !== 'Original') {
    await this.translate(recentText, this.targetLanguage, chunkId); // YENÄ° parametre
  }
}
```

#### **5. translate Fonksiyonunu GÃ¼ncelle:**
```javascript
// backend/server.js: satÄ±r ~350
async translate(text, targetLanguage, chunkId) { // YENÄ° parametre
  try {
    const shortContext = this.currentContext.slice(-200);
    
    const stream = await initializeOpenAI(process.env.OPENAI_API_KEY).chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: `Translate to ${targetLanguage}. Preserve names and brands. Context: ${shortContext}`,
        },
        {
          role: 'user',
          content: text,
        },
      ],
      max_tokens: 300,
      stream: true,
    });

    // Stream baÅŸladÄ± (ID ile)
    this.ws.send(JSON.stringify({
      type: 'translation_start',
      data: { 
        language: targetLanguage,
        for_chunk_id: chunkId // YENÄ°: Hangi chunk iÃ§in
      }
    }));

    // Stream translation (ID ile)
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || '';
      if (content) {
        this.ws.send(JSON.stringify({
          type: 'translation',
          data: {
            text: content,
            language: targetLanguage,
            partial: true,
            for_chunk_id: chunkId // YENÄ°
          },
        }));
      }
    }

    // Translation complete (ID ile)
    this.ws.send(JSON.stringify({
      type: 'translation',
      data: {
        language: targetLanguage,
        partial: false,
        for_chunk_id: chunkId // YENÄ°
      },
    }));

  } catch (error) {
    console.error('âŒ Translation failed:', error);
  }
}
```

#### **6. analyzeAndCorrect Fonksiyonunu GÃ¼ncelle:**
```javascript
// backend/server.js: satÄ±r ~245 (analyzeAndCorrect iÃ§inde, dÃ¼zeltme gÃ¶nderme kÄ±smÄ±)
async analyzeAndCorrect() {
  if (this.currentContext.length < 30) return;
  
  // ... mevcut analiz kodu (GPT Ã§aÄŸrÄ±sÄ± vs.)
  
  // DÃ¼zeltmeler bulundu
  if (result.corrections && result.corrections.length > 0) {
    // Ã–NCEDEN: Sadece corrections gÃ¶nderiliyordu
    // ÅÄ°MDÄ°: Hangi chunk'lara ait olduÄŸunu bul
    
    result.corrections.forEach(correction => {
      // Son 5 chunk'ta bu kelimeyi ara
      const affectedChunks = this.contextBuffer
        .slice(-5)
        .filter(chunk => chunk.text.includes(correction.original));
      
      // Her etkilenen chunk iÃ§in ayrÄ± dÃ¼zeltme gÃ¶nder
      affectedChunks.forEach(chunk => {
        this.ws.send(JSON.stringify({
          type: 'correction',
          data: {
            for_chunk_id: chunk.id, // YENÄ°: Hangi chunk dÃ¼zeltiliyor
            original: correction.original,
            corrected: correction.corrected,
            confidence: correction.confidence,
          },
        }));
        
        // Chunk map'te gÃ¼ncelle
        const mappedChunk = this.chunksMap.get(chunk.id);
        if (mappedChunk) {
          mappedChunk.corrected = true;
          mappedChunk.correctedText = correction.corrected;
        }
      });
    });
  }
}
```

#### **7. YENÄ° ENDPOINT: Retranslation**
```javascript
// backend/server.js: WebSocket message handler iÃ§ine ekle (satÄ±r ~450'den sonra)
case 'retranslate':
  console.log('ğŸ”„ Retranslation requested for chunk:', data.chunkId);
  
  const chunk = session.chunksMap.get(data.chunkId);
  if (chunk) {
    // DÃ¼zeltilmiÅŸ metni Ã§evir
    await session.translate(
      data.correctedText, 
      session.targetLanguage, 
      data.chunkId
    );
  } else {
    console.error('âŒ Chunk not found:', data.chunkId);
  }
  break;
```

---

### **Frontend: Unified State Management**

#### **1. State YapÄ±sÄ±nÄ± DeÄŸiÅŸtir:**
```javascript
// frontend/src/App.jsx: State tanÄ±mlamalarÄ± (satÄ±r ~10)

// âŒ ESKÄ°:
// const [transcript, setTranscript] = useState([]);
// const [translation, setTranslation] = useState('');

// âœ… YENÄ°: Unified chunks state
const [chunks, setChunks] = useState([]);

// Chunk yapÄ±sÄ±:
// {
//   id: 'chunk-123',
//   transcript: {
//     original: 'ka',
//     corrected: null,
//     timestamp: 1234567890,
//     status: 'pending' // pending, correcting, corrected
//   },
//   translation: {
//     text: '',
//     status: 'none', // none, translating, done, retranslating
//     timestamp: null
//   }
// }
```

#### **2. handleServerMessage Fonksiyonunu Yeniden Yaz:**
```javascript
// frontend/src/App.jsx: handleServerMessage fonksiyonu (satÄ±r ~100)
const handleServerMessage = (message) => {
  const now = Date.now();
  
  switch (message.type) {
    case 'status':
      setStatus(message.message);
      break;

    case 'transcript':
      // Gecikmeyi Ã¶lÃ§
      const sttLatency = now - lastTranscriptTimeRef.current;
      setLatencyStats(prev => ({ ...prev, stt: sttLatency }));
      lastTranscriptTimeRef.current = now;
      
      // YENÄ°: Chunk olarak ekle
      setChunks(prev => [...prev, {
        id: message.data.id, // Backend'den gelen ID
        transcript: {
          original: message.data.text,
          corrected: null,
          timestamp: message.data.timestamp,
          status: 'pending'
        },
        translation: {
          text: '',
          status: 'none',
          timestamp: null
        }
      }]);
      break;

    case 'translation_start':
      // YENÄ°: Bu chunk iÃ§in Ã§eviri baÅŸladÄ±
      setChunks(prev => prev.map(chunk => {
        if (chunk.id === message.data.for_chunk_id) {
          return {
            ...chunk,
            translation: {
              text: '',
              status: 'translating',
              timestamp: now
            }
          };
        }
        return chunk;
      }));
      break;

    case 'translation':
      if (message.data.partial) {
        // Streaming translation (kelime kelime)
        setChunks(prev => prev.map(chunk => {
          if (chunk.id === message.data.for_chunk_id) {
            return {
              ...chunk,
              translation: {
                text: chunk.translation.text + message.data.text,
                status: 'translating',
                timestamp: now
              }
            };
          }
          return chunk;
        }));
      } else {
        // Translation tamamlandÄ±
        setChunks(prev => prev.map(chunk => {
          if (chunk.id === message.data.for_chunk_id) {
            return {
              ...chunk,
              translation: {
                ...chunk.translation,
                status: 'done'
              }
            };
          }
          return chunk;
        }));
      }
      break;

    case 'correction':
      // DÃ¼zeltme geldi - EN KRÄ°TÄ°K KISIM!
      setChunks(prev => prev.map(chunk => {
        if (chunk.id === message.data.for_chunk_id) {
          return {
            ...chunk,
            transcript: {
              ...chunk.transcript,
              corrected: message.data.corrected,
              status: 'correcting' // Animasyon iÃ§in
            },
            translation: {
              ...chunk.translation,
              status: 'retranslating' // Ã‡OK Ã–NEMLÄ°: Eski Ã§eviriyi invalidate et
            }
          };
        }
        return chunk;
      }));
      
      // 1 saniye sonra animasyonu bitir
      setTimeout(() => {
        setChunks(prev => prev.map(chunk => 
          chunk.id === message.data.for_chunk_id 
            ? { ...chunk, transcript: { ...chunk.transcript, status: 'corrected' } }
            : chunk
        ));
      }, 1000);
      
      // YENÄ° Ã‡AÄRI: Backend'e retranslation iste
      if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'retranslate',
          chunkId: message.data.for_chunk_id,
          correctedText: message.data.corrected
        }));
      }
      break;
      
    case 'error':
      setStatus('Error: ' + message.message);
      console.error('âŒ Server error:', message.message);
      break;
      
    // ... diÄŸer case'ler (session.created, speech_started, vb.)
    
    default:
      console.log('ğŸ“¨ Unknown message type:', message.type);
  }
};
```

#### **3. UI BileÅŸenlerini GÃ¼ncelle:**
```jsx
// frontend/src/App.jsx: Render kÄ±smÄ± (satÄ±r ~400'den sonra)

// âŒ ESKÄ°: transcript.map() ve translation ayrÄ±
// âœ… YENÄ°: chunks.map() - her ÅŸey birlikte

<div className="flex-1 overflow-y-auto p-6 space-y-4">
  {/* Chunk-based gÃ¶sterim */}
  {chunks.map((chunk) => (
    <div 
      key={chunk.id} 
      className="bg-white rounded-lg shadow-sm p-4 border border-gray-100"
    >
      {/* Transcript (orijinal/dÃ¼zeltilmiÅŸ) */}
      <div className={`transcript-section mb-2 transition-all duration-500 ${
        chunk.transcript.status === 'correcting' ? 'scale-105' : ''
      }`}>
        <span className="text-xs text-gray-400 mr-2">ğŸ¤</span>
        {chunk.transcript.corrected ? (
          <span className={
            chunk.transcript.status === 'correcting' 
              ? 'text-yellow-500' 
              : 'text-green-600'
          }>
            <s className="text-gray-400">{chunk.transcript.original}</s>
            {' '}
            <span className="font-semibold">{chunk.transcript.corrected}</span>
          </span>
        ) : (
          <span className="text-gray-700">{chunk.transcript.original}</span>
        )}
      </div>

      {/* Translation */}
      <div className={`translation-section transition-all duration-300 ${
        chunk.translation.status === 'retranslating' 
          ? 'opacity-50' 
          : 'opacity-100'
      }`}>
        <span className="text-xs text-blue-400 mr-2">ğŸŒ</span>
        {chunk.translation.status === 'retranslating' ? (
          <span className="text-yellow-500 italic">
            â³ Re-translating...
          </span>
        ) : chunk.translation.status === 'none' ? (
          <span className="text-gray-300 italic">Waiting for translation...</span>
        ) : (
          <span className={
            chunk.translation.status === 'translating' 
              ? 'text-blue-600 animate-pulse' 
              : 'text-blue-800'
          }>
            {chunk.translation.text}
          </span>
        )}
      </div>

      {/* Timestamp (debug iÃ§in) */}
      <div className="text-xs text-gray-300 mt-1">
        ID: {chunk.id.slice(-8)} | {new Date(chunk.transcript.timestamp).toLocaleTimeString()}
      </div>
    </div>
  ))}
</div>
```

---

## **ADIM 1.1 & 1.2: Streaming Translation (Orijinal Plandan - DeÄŸiÅŸiklik Yok)**

> **NOT:** 7.11.2205.md'deki AdÄ±m 1.1 ve 1.2 **AYNEN KORUNUYOR**. Sadece state management atomik ID ile entegre edildi (yukarÄ±da).

---

## **ADIM 1.3: Testing - Real-time Performance + Atomik ID (GÃœNCELLENDÄ°)**

### **Test SenaryolarÄ±:**

**Test 1: Tek kelime Ã§eviri (orijinal)**
```
Input: "Merhaba"
Expected: "Hello" 0.5s iÃ§inde ekranda
Backend Log: chunk-xxx-0 created
Frontend: 1 chunk gÃ¶rÃ¼nÃ¼r, translation.status = 'done'
Result: âœ… / âŒ
```

**Test 2: DÃ¼zeltme + Retranslation (YENÄ° - EN Ã–NEMLÄ°!)**
```
Input: "Defterime ka yazdÄ±m"

Timeline:
0.0s: "Defterime" â†’ chunk-0 created
      Frontend: chunk-0 { transcript: "Defterime", translation: "To my notebook" }
      
0.5s: "ka" â†’ chunk-1 created
      Frontend: chunk-1 { transcript: "ka", translation: "because" } âŒ YANLIÅ
      
1.0s: "yazdÄ±m" â†’ chunk-2 created
      Frontend: chunk-2 { transcript: "yazdÄ±m", translation: "I wrote" }

2.0s: DÃ¼zeltme geldi: chunk-1 iÃ§in "ka" â†’ "kalem"
      Frontend: chunk-1 { 
        transcript: { original: "ka", corrected: "kalem", status: "correcting" },
        translation: { text: "because", status: "retranslating" } // INVALIDATE!
      }
      Backend: Retranslation request gÃ¶nderildi
      
2.5s: Yeni Ã§eviri geldi (chunk-1 iÃ§in)
      Frontend: chunk-1 { 
        transcript: { corrected: "kalem", status: "corrected" },
        translation: { text: "pen", status: "done" } âœ… DOÄRU!
      }

Final UI:
chunk-0: "Defterime" â†’ "To my notebook"
chunk-1: <s>ka</s> kalem â†’ <s>because</s> pen âœ…
chunk-2: "yazdÄ±m" â†’ "I wrote"

Result: âœ… / âŒ
```

**Test 3: Race Condition KontrolÃ¼ (YENÄ°)**
```
Input: "Benim ka var, baÅŸka ka aldÄ±m"

Backend Log:
- chunk-100: "Benim ka var" â†’ translation sent (for chunk-100)
- chunk-101: "baÅŸka ka aldÄ±m" â†’ translation sent (for chunk-101)

DÃ¼zeltme: Ä°lk "ka" â†’ "kalem" (chunk-100)
         Ä°kinci "ka" â†’ "kale" (chunk-101)

Frontend:
chunk-100: "ka" â†’ "kalem" âœ…
chunk-101: "ka" â†’ "kale" âœ…

Ã–NCEDEN: includes() ile HER Ä°KÄ° "ka" da "kalem" olurdu âŒ
ÅÄ°MDÄ°: ID ile doÄŸru chunk dÃ¼zeltilir âœ…

Result: âœ… / âŒ
```

**Metrikler:**
- First word latency: < 0.5s âœ…
- Correction â†’ Retranslation latency: < 1s âœ…
- Race condition: Yok âœ…
- Memory leak: Yok (chunks siliniyor mu? Test et!) âœ…

---

## **ADIM 1.4: Cleanup MekanizmasÄ± (YENÄ° - Bonus)**

> **NEDEN:** KullanÄ±cÄ± 1 saat konuÅŸursa 10000+ chunk birikir â†’ Memory problem!

### **Backend:**
```javascript
// backend/server.js: TranscriptionSession constructor'a ekle
constructor(ws) {
  // ... mevcut kod
  this.maxChunks = 200; // Son 200 chunk tut
  
  // Her 30 saniyede bir cleanup
  this.cleanupInterval = setInterval(() => {
    this.cleanupOldChunks();
  }, 30000);
}

cleanupOldChunks() {
  if (this.chunksMap.size > this.maxChunks) {
    // En eski chunk'larÄ± sil
    const allChunks = Array.from(this.chunksMap.entries());
    const toDelete = allChunks
      .sort((a, b) => a[1].timestamp - b[1].timestamp)
      .slice(0, allChunks.length - this.maxChunks)
      .map(([id]) => id);
    
    toDelete.forEach(id => {
      this.chunksMap.delete(id);
      console.log('ğŸ—‘ï¸ Deleted old chunk:', id);
    });
    
    // Frontend'e bildir
    this.ws.send(JSON.stringify({
      type: 'cleanup',
      data: { deletedChunks: toDelete }
    }));
  }
}

disconnect() {
  // Cleanup interval'Ä± temizle
  if (this.cleanupInterval) {
    clearInterval(this.cleanupInterval);
  }
  
  if (this.realtimeWs) {
    this.realtimeWs.close();
  }
}
```

### **Frontend:**
```javascript
// frontend/src/App.jsx: handleServerMessage'a ekle
case 'cleanup':
  // Backend eski chunk'larÄ± sildi, frontend'de de sil
  setChunks(prev => prev.filter(
    chunk => !message.data.deletedChunks.includes(chunk.id)
  ));
  console.log('ğŸ—‘ï¸ Cleaned up old chunks:', message.data.deletedChunks.length);
  break;
```

---

# HAFTA 2: DÄ°NAMÄ°K PROMPT (GLOBAL) - REVÄ°ZE

## **DEÄÄ°ÅÄ°KLÄ°K: extractKeywords ve topicMap KALDIRILDÄ°**

### **ESKÄ° Kod (7.11.2205.md satÄ±r 460-525):**
```javascript
function extractKeywords(text) {
  const stopWords = ['the', 'a', 've', 'bir', 'bu']; // âŒ Dil-spesifik
  // ...
}

function detectTopicsFromKeywords(keywords) {
  const topicMap = { ... }; // âŒ Manuel pattern
}
```

### **YENÄ° Kod:**
```javascript
// backend/server.js: YENÄ° fonksiyon ekle

async function buildDynamicPrompt(transcript, context, openaiClient) {
  // ADIM 1: GPT ile keyword extraction (multi-language)
  const keywordResponse = await openaiClient.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{
      role: 'user',
      content: `Extract 5-10 key topics, entities, or important words from this text. Ignore common filler words. Return comma-separated list:

"${context}"

Key topics/entities:`
    }],
    max_tokens: 50,
    temperature: 0.3
  });
  
  const keywords = keywordResponse.choices[0].message.content.trim();
  
  console.log('ğŸ”‘ Extracted keywords:', keywords);
  
  // ADIM 2: Prompt oluÅŸtur (topicMap yok!)
  const prompt = `You are an expert at correcting speech transcription errors.

Context (last 60 seconds):
"${context}"

Detected key topics/entities: ${keywords}

Recent transcript to analyze:
"${transcript}"

Task:
1. Identify uncertain or incorrect words in the recent transcript
2. Use the context and detected topics to find the most likely correction
3. Consider:
   - Phonetic similarity (homophones like "pen/pain", "ka/kalem")
   - Semantic meaning in context
   - Common transcription errors
   - Names, places, organizations (preserve them!)
   - Language-specific patterns

Return JSON:
{
  "corrections": [
    {
      "original": "incorrect word",
      "corrected": "correct word",
      "confidence": 0.95,
      "reason": "brief explanation"
    }
  ]
}

If no corrections needed, return empty array.`;

  return prompt;
}
```

### **analyzeAndCorrect'i GÃ¼ncelle:**
```javascript
// backend/server.js: analyzeAndCorrect fonksiyonu (satÄ±r ~245)
async analyzeAndCorrect() {
  if (this.currentContext.length < 30) return;
  
  // Cache check (mevcut kod aynÄ±)
  const recentContext = this.contextBuffer
    .slice(-5)
    .map(item => item.text)
    .join(' ');
  
  const cacheKey = recentContext.slice(-100);
  if (this.correctionCache.has(cacheKey)) {
    console.log('ğŸ’¾ Using cached correction');
    return;
  }
  
  try {
    // YENÄ°: Dynamic prompt builder kullan
    const prompt = await buildDynamicPrompt(
      recentContext, 
      this.currentContext,
      initializeOpenAI(process.env.OPENAI_API_KEY)
    );
    
    // GPT'ye sor
    const response = await initializeOpenAI(process.env.OPENAI_API_KEY).chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{
        role: 'user',
        content: prompt
      }],
      response_format: { type: 'json_object' },
      temperature: 0.3,
      max_tokens: 500,
    });

    const result = JSON.parse(response.choices[0].message.content);
    
    // ... geri kalan kod aynÄ± (dÃ¼zeltmeleri gÃ¶nder)
    
  } catch (error) {
    console.error('âŒ Analysis failed:', error);
  }
}
```

### **Test (Multi-language):**

**Test 1: TÃ¼rkÃ§e (Orijinal problem)**
```
Context: "Kitap okuyorum. Yazar gÃ¼zel anlatmÄ±ÅŸ. Kitapda derece hikaye var."

GPT Keyword Extraction:
â†’ "kitap, yazar, anlatmÄ±ÅŸ, hikaye"

Dynamic Prompt:
"Detected topics: kitap, yazar, anlatmÄ±ÅŸ, hikaye"
"Recent transcript: Kitapda derece hikaye var"

GPT Correction:
{
  "corrections": [{
    "original": "derece",
    "corrected": "diyorki",
    "confidence": 0.92,
    "reason": "Context suggests book content pattern 'kitapda [says]', phonetically similar"
  }]
}

Result: âœ… (manuel pattern olmadan Ã§Ã¶zdÃ¼!)
```

**Test 2: FransÄ±zca**
```
Context: "Je veux du pain. Le boulanger fait du pain chaud."

GPT Keyword Extraction:
â†’ "pain, boulanger, chaud"

Dynamic Prompt:
"Detected topics: pain, boulanger, chaud"
"Recent transcript: Je veux du pen"

GPT Correction:
{
  "corrections": [{
    "original": "pen",
    "corrected": "pain",
    "confidence": 0.95,
    "reason": "Context about bakery and bread, 'pen' doesn't fit semantically"
  }]
}

Result: âœ… (FransÄ±zca iÃ§in de Ã§alÄ±ÅŸtÄ±!)
```

**Test 3: Ä°ngilizce (NBA problemi)**
```
Context: "NBA playoffs are exciting. Lakers won the game."

GPT Keyword Extraction:
â†’ "NBA, playoffs, Lakers, game"

Dynamic Prompt:
"Detected topics: NBA, playoffs, Lakers, game"
"Recent transcript: NBC championship"

GPT Correction:
{
  "corrections": [{
    "original": "NBC",
    "corrected": "NBA",
    "confidence": 0.93,
    "reason": "Sports context with playoffs/Lakers suggests NBA, not news network NBC"
  }]
}

Result: âœ…
```

### **Maliyet Analizi:**
```
Eski YÃ¶ntem (Manuel):
- extractKeywords: $0 (local)
- analyzeAndCorrect: $0.00025 (GPT-4o-mini)
Toplam: $0.00025

Yeni YÃ¶ntem (GPT-based):
- Keyword extraction: ~50 tokens = $0.000025
- analyzeAndCorrect: $0.00025
Toplam: $0.000275

Fark: $0.000025 per request (%10 artÄ±ÅŸ)

ANCAK:
- %100 multi-language âœ…
- Daha akÄ±llÄ± context understanding âœ…
- Manuel pattern maintenance yok âœ…
- Her dil iÃ§in ayrÄ± stopWords listesi yok âœ…

Karar: âœ… Maliyet artÄ±ÅŸÄ± KABUL EDÄ°LEBÄ°LÄ°R
```

---

# HAFTA 3: EMBEDDING HÄ°BRÄ°T (REVÄ°ZE) - CANDIDATES YOK

## **KRÄ°TÄ°K DEÄÄ°ÅÄ°KLÄ°K: generateCandidates KaldÄ±rÄ±ldÄ±**

### **PROBLEM (ESKÄ° Plan):**
```
generateCandidates("ka") â†’ GPT'ye sor â†’ ["kalem", "kale", "kaÄŸÄ±t"]
                            â†“
                        300ms, $0.0001

Sonra Embedding check â†’ 50ms, $0.00002

TOPLAM: 350ms, $0.00012 (GPT + Embedding)
```

**AI'nÄ±n eleÅŸtirisi:** "Bu, Hafta 3'Ã¼n amacÄ±nÄ± (maliyet azaltma) yok eder!"

---

### **YENÄ° YAKLAÅIM: Context Similarity (GPT'siz)**

```
Belirsiz kelime: "ka"
Context: "defter yazdÄ±m"

Context similarity check:
- "ka" embedding â†” "defter yazdÄ±m" embedding = 0.45 (dÃ¼ÅŸÃ¼k)
  â†“
Decision: LIKELY_WRONG â†’ GPT'ye sor

---

Kesin kelime: "Ekrem"
Context: "benim adÄ±m"

Context similarity check:
- "Ekrem" embedding â†” "benim adÄ±m" embedding = 0.88 (yÃ¼ksek)
  â†“
Decision: ACCEPT_AS_IS â†’ GPT'ye GÄ°TME! âš¡

KazanÃ§: 50ms, $0.00002 (sadece embedding)
```

---

### **Implementasyon:**

#### **1. EmbeddingCache SÄ±nÄ±fÄ± (Orijinal Plandan - AynÄ±):**
```javascript
// backend/server.js: EmbeddingCache sÄ±nÄ±fÄ± ekle
class EmbeddingCache {
  constructor() {
    this.cache = new Map();
    this.maxSize = 1000;
    this.ttl = 3600000; // 1 saat
  }
  
  async getEmbedding(text, openaiClient) {
    const key = text.toLowerCase().trim();
    
    if (this.cache.has(key)) {
      const cached = this.cache.get(key);
      if (Date.now() - cached.timestamp < this.ttl) {
        return cached.embedding; // Cache hit! âš¡
      }
    }
    
    // Cache miss: API call
    const response = await openaiClient.embeddings.create({
      model: "text-embedding-3-small",
      input: text
    });
    
    const embedding = response.data[0].embedding;
    
    this.cache.set(key, {
      embedding,
      timestamp: Date.now()
    });
    
    if (this.cache.size > this.maxSize) {
      const firstKey = this.cache.keys().next().value;
      this.cache.delete(firstKey);
    }
    
    return embedding;
  }
}

// Global instance
const embeddingCache = new EmbeddingCache();

function cosineSimilarity(a, b) {
  const dot = a.reduce((sum, val, i) => sum + val * b[i], 0);
  const normA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
  const normB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
  return dot / (normA * normB);
}
```

#### **2. YENÄ°: checkWithEmbedding (Context Similarity):**
```javascript
// backend/server.js: YENÄ° fonksiyon

async function checkWithEmbedding(uncertainWord, context, openaiClient) {
  // 1. Belirsiz kelimenin embedding'i
  const wordEmbed = await embeddingCache.getEmbedding(uncertainWord, openaiClient);
  
  // 2. Context'in embedding'i
  const contextEmbed = await embeddingCache.getEmbedding(context, openaiClient);
  
  // 3. Similarity check
  const similarity = cosineSimilarity(wordEmbed, contextEmbed);
  
  console.log(`ğŸ“Š Embedding similarity for "${uncertainWord}": ${similarity.toFixed(2)}`);
  
  // 4. Three-tier decision
  if (similarity >= 0.85) {
    // Ã‡ok uyumlu, muhtemelen doÄŸru
    return {
      action: 'ACCEPT_AS_IS',
      confidence: similarity,
      method: 'embedding',
      word: uncertainWord
    };
  } else if (similarity < 0.50) {
    // Ã‡ok uyumsuz, muhtemelen yanlÄ±ÅŸ
    return {
      action: 'LIKELY_WRONG_ASK_GPT',
      confidence: similarity,
      method: 'need_gpt'
    };
  } else {
    // Belirsiz bÃ¶lge (0.50-0.85)
    return {
      action: 'UNCERTAIN_ASK_GPT',
      confidence: similarity,
      method: 'need_gpt'
    };
  }
}
```

#### **3. correctWithHybrid Fonksiyonu (Revize):**
```javascript
// backend/server.js: YENÄ° fonksiyon

async function correctWithHybrid(uncertainWord, context, openaiClient) {
  // ADIM 1: Embedding pre-filter
  const embeddingResult = await checkWithEmbedding(
    uncertainWord,
    context,
    openaiClient
  );
  
  if (embeddingResult.action === 'ACCEPT_AS_IS') {
    // Kolay durum: Kelime context ile uyumlu, doÄŸru olarak kabul et
    console.log(`âœ… "${uncertainWord}" accepted (embedding confidence: ${embeddingResult.confidence.toFixed(2)})`);
    return {
      correction: uncertainWord, // DeÄŸiÅŸtirme!
      confidence: embeddingResult.confidence,
      method: 'embedding',
      fast: true
    };
  } else {
    // Zor durum: GPT'ye sor
    console.log(`ğŸ¤” "${uncertainWord}" uncertain, asking GPT (embedding: ${embeddingResult.confidence.toFixed(2)})`);
    
    const gptResult = await askGPTForCorrection(
      uncertainWord,
      context,
      embeddingResult.confidence, // Embedding skorunu ver
      openaiClient
    );
    
    return {
      correction: gptResult.correction,
      confidence: gptResult.confidence,
      method: 'gpt',
      fast: false
    };
  }
}
```

#### **4. askGPTForCorrection (Revize - Embedding skorunu kullan):**
```javascript
// backend/server.js: YENÄ° fonksiyon

async function askGPTForCorrection(word, context, embeddingSimilarity, openaiClient) {
  const prompt = `Correct this uncertain word in context:

Word: "${word}"
Context: "${context}"

Embedding analysis: Similarity score is ${embeddingSimilarity.toFixed(2)} (0.0-1.0 scale).
${embeddingSimilarity < 0.50 
  ? 'Low similarity suggests the word is likely incorrect or out of context.' 
  : 'Medium similarity suggests the word might be correct or needs minor correction.'}

Task: Determine if the word needs correction. Consider:
- Phonetic similarity to context-appropriate words
- Semantic fit with the context
- Common transcription errors
- Language patterns

Return JSON:
{
  "correction": "corrected word (or same if correct)",
  "confidence": 0.95,
  "reason": "brief explanation",
  "changed": true/false
}`;

  const response = await openaiClient.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' },
    temperature: 0.3,
    max_tokens: 150
  });
  
  const result = JSON.parse(response.choices[0].message.content);
  
  return {
    correction: result.correction,
    confidence: result.confidence,
    changed: result.changed
  };
}
```

#### **5. analyzeAndCorrect'e Entegre Et:**
```javascript
// backend/server.js: analyzeAndCorrect fonksiyonuna ekle

async analyzeAndCorrect() {
  // ... mevcut kod (dynamic prompt, GPT call)
  
  const result = JSON.parse(response.choices[0].message.content);
  
  if (result.corrections && result.corrections.length > 0) {
    // YENÄ°: Her dÃ¼zeltmeyi embedding ile filtrele
    const filteredCorrections = [];
    
    for (const correction of result.corrections) {
      // Embedding hybrid check
      const hybridResult = await correctWithHybrid(
        correction.original,
        this.currentContext,
        initializeOpenAI(process.env.OPENAI_API_KEY)
      );
      
      // EÄŸer gerÃ§ekten deÄŸiÅŸiklik varsa ekle
      if (hybridResult.correction !== correction.original) {
        filteredCorrections.push({
          original: correction.original,
          corrected: hybridResult.correction,
          confidence: hybridResult.confidence,
          method: hybridResult.method
        });
      } else if (hybridResult.method === 'gpt') {
        // GPT deÄŸiÅŸtirmedi, embedding de uyumluydu
        console.log(`âœ… "${correction.original}" confirmed correct by GPT+Embedding`);
      }
    }
    
    // Sadece gerÃ§ek dÃ¼zeltmeleri gÃ¶nder
    if (filteredCorrections.length > 0) {
      filteredCorrections.forEach(correction => {
        // ... chunk'lara gÃ¶nder (Hafta 1'deki kod)
      });
    }
  }
}
```

---

### **Maliyet ve HÄ±z KarÅŸÄ±laÅŸtÄ±rmasÄ±:**

```
100 belirsiz kelime senaryosu:

ESKÄ° PLAN (generateCandidates + Embedding):
1. generateCandidates: 100 Ã— GPT = 30s, $0.01
2. Embedding check: 100 Ã— 50ms = 5s, $0.002
3. GPT fallback (40%): 40 Ã— GPT = 12s, $0.004
TOPLAM: 47s, $0.016

YENÄ° PLAN (Context Similarity):
1. Embedding check: 100 Ã— 50ms = 5s, $0.002
2. ACCEPT_AS_IS (60%): 0s, $0 âš¡
3. GPT fallback (40%): 40 Ã— GPT = 12s, $0.004
TOPLAM: 17s, $0.006

KAZANÃ‡: %64 hÄ±zlanma, %62 maliyet azalmasÄ± âœ…
```

**GerÃ§ekÃ§i Senaryo (Embedding cache ile):**
```
Cache hit rate: %80 (aynÄ± kelimeler tekrar ediyor)

YENÄ° PLAN (Cache ile):
1. Embedding check: 
   - 20 cache miss Ã— 50ms = 1s, $0.0004
   - 80 cache hit Ã— 1ms = 0.08s, $0
2. ACCEPT_AS_IS (60): 0s, $0
3. GPT fallback (40): 40 Ã— 300ms = 12s, $0.004
TOPLAM: 13s, $0.0044

ESKÄ° YÃ–NTEM (Her zaman GPT):
100 Ã— GPT = 30s, $0.01

KAZANÃ‡: %57 hÄ±zlanma, %56 maliyet azalmasÄ± âœ…
```

---

# HAFTA 4: RETROACTIVE CORRECTION + TTL - REVÄ°ZE

## **YENÄ° ADIM 4.0: TTL Queue (GÃ¼n 0.5 - Memory Leak Ã–nleme)**

### **PendingCorrectionsQueue SÄ±nÄ±fÄ± (Revize):**
```javascript
// backend/server.js: YENÄ° sÄ±nÄ±f ekle

class PendingCorrectionsQueue {
  constructor(ws, openaiClient) {
    this.ws = ws;
    this.openaiClient = openaiClient;
    this.queue = [];
    this.maxWaitTime = 15000; // 15 saniye
    this.checkInterval = 5000; // 5 saniyede bir kontrol
    
    // Otomatik TTL checker baÅŸlat
    this.ttlChecker = setInterval(() => {
      this.checkQueueTTL();
    }, this.checkInterval);
  }
  
  add(word, context, timestamp, chunkId) {
    this.queue.push({
      word,
      context,
      timestamp,
      chunkId, // YENÄ°: Atomik ID ile entegrasyon
      waitingForFutureContext: true
    });
    
    console.log(`ğŸ“Œ Added to pending queue: "${word}" (chunk: ${chunkId})`);
  }
  
  async checkQueueTTL() {
    const now = Date.now();
    const expiredItems = [];
    
    // SÃ¼resi dolan itemlarÄ± bul
    this.queue = this.queue.filter(item => {
      const age = now - item.timestamp;
      
      if (age > this.maxWaitTime) {
        expiredItems.push(item);
        return false; // Kuyruktan Ã§Ä±kar
      }
      return true; // Kuyrukta tut
    });
    
    // SÃ¼resi dolanlar iÃ§in "best guess" dÃ¼zeltme
    for (const item of expiredItems) {
      console.log(`â° TTL expired for "${item.word}" (waited ${this.maxWaitTime}ms)`);
      
      // Son analiz (future context olmadan)
      const result = await correctWithHybrid(
        item.word,
        item.context,
        this.openaiClient
      );
      
      if (result.confidence > 0.70) {
        // DÃ¼ÅŸÃ¼k gÃ¼ven bile olsa dÃ¼zelt
        console.log(`ğŸ”§ Final decision: "${item.word}" â†’ "${result.correction}" (conf: ${result.confidence.toFixed(2)})`);
        this.sendCorrection(item.chunkId, item.word, result.correction, result.confidence);
      } else {
        // Ã‡ok belirsiz, olduÄŸu gibi bÄ±rak
        console.log(`â“ Too uncertain (${result.confidence.toFixed(2)}), keeping "${item.word}" as-is`);
      }
    }
    
    if (expiredItems.length > 0) {
      console.log(`ğŸ—‘ï¸ Cleaned up ${expiredItems.length} expired items from queue`);
    }
  }
  
  async checkWithFutureContext(newSentence, newContext) {
    const itemsToRemove = [];
    
    // Queue'daki her pending item iÃ§in
    for (const pending of this.queue) {
      // Yeni cÃ¼mleyi context'e ekle
      const expandedContext = pending.context + ' ' + newContext;
      
      // Yeniden deÄŸerlendir
      const result = await correctWithHybrid(
        pending.word,
        expandedContext,
        this.openaiClient
      );
      
      if (result.confidence > 0.90) {
        // ArtÄ±k eminiz, dÃ¼zelt!
        console.log(`âœ¨ Future context resolved: "${pending.word}" â†’ "${result.correction}" (conf: ${result.confidence.toFixed(2)})`);
        this.sendCorrection(pending.chunkId, pending.word, result.correction, result.confidence);
        itemsToRemove.push(pending);
      }
    }
    
    // Ã‡Ã¶zÃ¼len itemlarÄ± kuyruktan Ã§Ä±kar
    this.queue = this.queue.filter(item => !itemsToRemove.includes(item));
  }
  
  sendCorrection(chunkId, original, corrected, confidence) {
    this.ws.send(JSON.stringify({
      type: 'correction',
      data: {
        for_chunk_id: chunkId, // Atomik ID ile
        original,
        corrected,
        confidence,
        source: 'pending_queue' // Debug iÃ§in
      }
    }));
  }
  
  cleanup() {
    if (this.ttlChecker) {
      clearInterval(this.ttlChecker);
    }
  }
}
```

### **TranscriptionSession'a Entegre Et:**
```javascript
// backend/server.js: TranscriptionSession constructor
constructor(ws) {
  // ... mevcut kod
  this.pendingQueue = new PendingCorrectionsQueue(
    ws,
    initializeOpenAI(process.env.OPENAI_API_KEY)
  ); // YENÄ°
}

// handleRealtimeEvent iÃ§ine ekle
case 'conversation.item.input_audio_transcription.completed':
  // ... mevcut kod
  
  // YENÄ°: Future context check (her yeni transcript'te)
  if (this.contextBuffer.length > 0) {
    await this.pendingQueue.checkWithFutureContext(
      transcript,
      this.currentContext
    );
  }
  break;

// disconnect fonksiyonuna ekle
disconnect() {
  if (this.pendingQueue) {
    this.pendingQueue.cleanup(); // YENÄ°
  }
  
  if (this.cleanupInterval) {
    clearInterval(this.cleanupInterval);
  }
  
  if (this.realtimeWs) {
    this.realtimeWs.close();
  }
}
```

### **analyzeAndCorrect'e Pending Logic Ekle:**
```javascript
// backend/server.js: analyzeAndCorrect fonksiyonuna ekle

async analyzeAndCorrect() {
  // ... mevcut analiz kodu
  
  if (result.corrections && result.corrections.length > 0) {
    for (const correction of result.corrections) {
      const hybridResult = await correctWithHybrid(
        correction.original,
        this.currentContext,
        initializeOpenAI(process.env.OPENAI_API_KEY)
      );
      
      // YENÄ°: Confidence dÃ¼ÅŸÃ¼kse pending queue'ya ekle
      if (hybridResult.confidence < 0.85 && hybridResult.confidence > 0.50) {
        // Belirsiz, future context bekle
        const affectedChunks = this.contextBuffer
          .slice(-5)
          .filter(chunk => chunk.text.includes(correction.original));
        
        affectedChunks.forEach(chunk => {
          this.pendingQueue.add(
            correction.original,
            this.currentContext,
            Date.now(),
            chunk.id
          );
        });
        
        console.log(`â³ Low confidence (${hybridResult.confidence.toFixed(2)}), added to pending queue`);
      } else if (hybridResult.confidence >= 0.85) {
        // YÃ¼ksek gÃ¼ven, hemen dÃ¼zelt
        // ... chunk'lara gÃ¶nder (Hafta 1'deki kod)
      }
      // confidence < 0.50 ise zaten GPT Ã§Ã¶zdÃ¼ veya kabul etti
    }
  }
}
```

---

### **Test (TTL ve Future Context):**

**Test 1: Future Context Success**
```
t=0s: "Benim karyolam araba dizaynlÄ±"
      â†’ "karyolam" belirsiz (confidence: 0.60)
      â†’ Pending queue'ya ekle

Backend Log:
ğŸ“Œ Added to pending queue: "karyolam" (chunk: chunk-xxx-5)

t=3s: "Ã‡ocukken istemiÅŸim"
      â†’ Future context check â†’ confidence: 0.65 (hala belirsiz)
      
Backend Log:
â³ Future context checked, still uncertain (0.65)

t=6s: "Arabada yatmak havalÄ±"
      â†’ "yatmak" kelimesi geldi!
      â†’ Future context check â†’ confidence: 0.95 âœ…
      
Backend Log:
âœ¨ Future context resolved: "karyolam" â†’ "karyolam" (conf: 0.95)
ğŸ”§ Correction sent to chunk: chunk-xxx-5

Frontend:
chunk-xxx-5: <s>karyolam</s> â†’ karyolam (deÄŸiÅŸmedi, doÄŸruydu!)

Result: âœ…
```

**Test 2: TTL Expiration**
```
t=0s: "Benim karayolam var"
      â†’ "karayolam" belirsiz (confidence: 0.55)
      â†’ Pending queue'ya ekle

Backend Log:
ğŸ“Œ Added to pending queue: "karayolam" (chunk: chunk-xxx-10)

t=5s, 10s: (Sessizlik, yeni context yok)
      â†’ Future context check â†’ confidence: hala 0.55
      
t=15s: TTL expired!
      â†’ Final decision (context yok)
      â†’ confidence: 0.75 â†’ "karayolam" â†’ "karyolam"
      
Backend Log:
â° TTL expired for "karayolam" (waited 15000ms)
ğŸ”§ Final decision: "karayolam" â†’ "karyolam" (conf: 0.75)

Frontend:
chunk-xxx-10: <s>karayolam</s> karyolam

Result: âœ… / âŒ (context yok ama makul tahmin)
```

**Test 3: Memory Leak Prevention**
```
Senaryo: KullanÄ±cÄ± 1 saat konuÅŸuyor, 100 belirsiz kelime var

t=0s-60s: 100 kelime pending queue'ya eklendi
          â†’ checkQueueTTL her 5s'de Ã§alÄ±ÅŸÄ±yor
          
t=15s: Ä°lk batch (15s Ã¶nce eklenenler) TTL expired
       â†’ 20 kelime cleaned up
       
Backend Log:
ğŸ—‘ï¸ Cleaned up 20 expired items from queue

t=30s: Ä°kinci batch TTL expired
       â†’ 25 kelime cleaned up
       
Queue size: 0-100 arasÄ± dinamik (sÃ¼rekli temizleniyor)
Memory: Stable âœ…

Result: âœ… Memory leak yok
```

---

## ğŸ“Š REVÄ°ZE EDÄ°LMÄ°Å PLAN - FINAL KAZANÃ‡LAR

### **HÄ±z:**
- Ä°lk kelime: 5s â†’ 0.5s (%90 hÄ±zlanma) âš¡âš¡âš¡
- Embedding + Cache: 300ms â†’ 50ms (%83 hÄ±zlanma) âš¡âš¡
- Candidate generation: ATLADIK (300ms tasarruf) âš¡

**TOPLAM: Ã–nceki plandan %30 daha hÄ±zlÄ±!**

---

### **Maliyet:**
- Embedding cache: %90 API call azalmasÄ±
- Candidate generation: %100 azalma (kaldÄ±rÄ±ldÄ±!)
- Keyword extraction: %10 artÄ±ÅŸ (GPT-based)

**NET KAZANÃ‡: %65 maliyet azalmasÄ±** (Ã¶nceki plan: %70, ama generateCandidates dahildi)

---

### **DoÄŸruluk:**
- Atomik ID: Race condition %100 Ã§Ã¶zÃ¼ldÃ¼ âœ…
- Global dil: Multi-language %100 Ã§alÄ±ÅŸÄ±r âœ…
- Context similarity: Daha akÄ±llÄ± filtre âœ…
- TTL queue: Memory leak yok âœ…

**TOPLAM: Ã–nceki plandan %20 daha gÃ¼venilir sistem!**

---

## âœ… SEG ONAYI GEREKLÄ°!

**YapÄ±lacaklar:**
1. âœ… PlanÄ± oku ve onayla
2. âœ… Hafta 1'e baÅŸla (backend/server.js + frontend/App.jsx)
3. âœ… Test et (3 senaryo)
4. âœ… Hafta 2, 3, 4 sÄ±rayla

**HazÄ±r mÄ±sÄ±n? Ä°lk commit'i atalÄ±m mÄ±?** ğŸš€
